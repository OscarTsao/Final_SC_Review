# HPO Inference v2 config with decoupled retrieval/rerank pool sizes
#
# Key changes from v1:
# - Added top_k_rerank as separate parameter from top_k_retriever
# - Allows tuning "big recall pool -> small rerank pool" pattern

paths:
  data_dir: data
  groundtruth: data/groundtruth/evidence_sentence_groundtruth.csv
  sentence_corpus: data/groundtruth/sentence_corpus.jsonl
  criteria: data/DSM5/MDD_Criteira.json
  hpo_cache_dir: outputs/hpo_cache
  hpo_output_dir: outputs/hpo

models:
  bge_m3: BAAI/bge-m3
  bge_query_max_length: 128
  bge_passage_max_length: 256
  bge_use_fp16: true
  bge_batch_size: 64

reranker:
  model_name: jinaai/jina-reranker-v3
  chunk_size: 64
  dtype: auto
  max_length: 512

cache:
  # Increase superset to accommodate larger retriever pools
  dense_topk_max: 200
  sparse_topk_max: 200
  superset_max: 200
  use_sparse: true
  use_multiv: true
  rebuild_embeddings: false
  # Trim method for candidate selection when superset > union size
  # Options: dense (default, legacy), rrf_dense_sparse, max_normalized
  trim_method: rrf_dense_sparse

split:
  seed: 42
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  dev_split: val

evaluation:
  ks: [1, 5, 10, 20]
  skip_no_positives: true

hpo:
  objective_metric: ndcg@10_reranked
  prune_chunk_frac: 0.1
  prune_min_queries: 50

search_space:
  # Retriever pool size - how many candidates to retrieve
  top_k_retriever: [32, 64, 100, 128, 150, 200]
  # Rerank pool size - how many to pass to reranker (must be <= retriever)
  top_k_rerank: [16, 32, 50, 64, 100]
  # Final output size
  top_k_final: [1, 3, 5, 10, 20]
  # Signal selection
  use_sparse: [true, false]
  use_multiv: [true, false]
  # Fusion
  fusion_method: [weighted_sum, rrf]
  score_normalization: [none, minmax_per_query, zscore_per_query]
  rrf_k: 60
