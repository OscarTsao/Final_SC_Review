# MAXOUT++ Budget Configuration
# Aggressive but efficient defaults for pushing beyond current best
# Auto-scales down based on VRAM and OOM detection

# Budget levels
quick:
  inference_hpo_trials: 1000
  reranker_hpo_trials: 50
  retriever_hpo_trials: 20
  multiquery_paraphrases_per_criterion: 4
  ensemble_max_base_models: 10
  gnn_sweep_configs: 30
  postprocess_hpo_trials: 1000
  retriever_zoo_top_k_max: 200

standard:
  inference_hpo_trials: 10000
  reranker_hpo_trials: 200
  retriever_hpo_trials: 50
  multiquery_paraphrases_per_criterion: 8
  ensemble_max_base_models: 20
  gnn_sweep_configs: 100
  postprocess_hpo_trials: 5000
  retriever_zoo_top_k_max: 400

maxout:
  # Inference HPO - Multi-fidelity: 20% dev -> 100% dev for top 2%
  inference_hpo_trials: 50000
  inference_hpo_early_stop_frac: 0.02
  inference_hpo_fidelity_levels: [0.2, 0.5, 1.0]

  # Reranker training HPO - ASHA pruning
  reranker_hpo_trials: 500
  reranker_hpo_top_full_eval: 10
  reranker_hpo_top_seeds: 3
  reranker_seeds: 5

  # Retriever finetune HPO - ASHA pruning
  retriever_hpo_trials: 200
  retriever_hpo_top_full_eval: 5
  retriever_hpo_top_seeds: 2
  retriever_seeds: 3

  # Multi-query paraphrase generation
  multiquery_paraphrases_per_criterion: 12
  multiquery_min_paraphrases: 8
  multiquery_max_paraphrases: 20

  # Ensemble stacking
  ensemble_max_base_models: 30
  ensemble_cv_folds: 5

  # GNN sweep
  gnn_sweep_configs: 300
  gnn_top_full_eval: 10
  gnn_top_seeds: 3

  # Postprocessing threshold HPO (CPU, fast)
  postprocess_hpo_trials: 10000

  # Retriever zoo
  retriever_zoo_top_k_max: 800
  retriever_zoo_oracle_ks: [50, 100, 200, 400, 800]

exhaustive:
  # Maximum budgets for final paper submission
  inference_hpo_trials: 100000
  inference_hpo_early_stop_frac: 0.01
  inference_hpo_fidelity_levels: [0.1, 0.25, 0.5, 1.0]

  reranker_hpo_trials: 1000
  reranker_hpo_top_full_eval: 20
  reranker_hpo_top_seeds: 5
  reranker_seeds: 10

  retriever_hpo_trials: 500
  retriever_hpo_top_full_eval: 10
  retriever_hpo_top_seeds: 3
  retriever_seeds: 5

  multiquery_paraphrases_per_criterion: 20
  multiquery_min_paraphrases: 10
  multiquery_max_paraphrases: 30

  ensemble_max_base_models: 50
  ensemble_cv_folds: 10

  gnn_sweep_configs: 500
  gnn_top_full_eval: 20
  gnn_top_seeds: 5

  postprocess_hpo_trials: 50000

  retriever_zoo_top_k_max: 1000
  retriever_zoo_oracle_ks: [50, 100, 200, 400, 600, 800, 1000]

# Auto-scaling thresholds based on VRAM
vram_scaling:
  # Scale factors for different VRAM tiers
  tier_32gb_plus:  # RTX 5090, A100
    scale_factor: 1.0
    batch_size_scale: 1.0
    max_retriever_batch: 256
    max_reranker_chunk: 128

  tier_24gb:  # RTX 4090
    scale_factor: 0.8
    batch_size_scale: 0.75
    max_retriever_batch: 192
    max_reranker_chunk: 96

  tier_16gb:  # RTX 4080
    scale_factor: 0.6
    batch_size_scale: 0.5
    max_retriever_batch: 128
    max_reranker_chunk: 64

  tier_12gb:  # RTX 3080
    scale_factor: 0.5
    batch_size_scale: 0.5
    max_retriever_batch: 64
    max_reranker_chunk: 32

  tier_8gb:  # RTX 3070
    scale_factor: 0.25
    batch_size_scale: 0.25
    max_retriever_batch: 32
    max_reranker_chunk: 16

# Retriever zoo candidates
retriever_zoo:
  candidates:
    - name: bge-m3
      model_id: BAAI/bge-m3
      type: hybrid
      priority: 1

    - name: bge-large-en-v1.5
      model_id: BAAI/bge-large-en-v1.5
      type: dense
      priority: 2

    - name: e5-large-v2
      model_id: intfloat/e5-large-v2
      type: dense
      priority: 3

    - name: gte-large-en-v1.5
      model_id: Alibaba-NLP/gte-large-en-v1.5
      type: dense
      priority: 4

    - name: stella-en-1.5B-v5
      model_id: dunzhang/stella_en_1.5B_v5
      type: dense
      priority: 5
      vram_min_gb: 16

    - name: nomic-embed-text-v1.5
      model_id: nomic-ai/nomic-embed-text-v1.5
      type: dense
      priority: 6

    - name: bm25
      model_id: bm25
      type: lexical
      priority: 7

# Reranker candidates
reranker_zoo:
  candidates:
    - name: jina-reranker-v3
      model_id: jinaai/jina-reranker-v3
      lora_compatible: true
      priority: 1

    - name: bge-reranker-v2-m3
      model_id: BAAI/bge-reranker-v2-m3
      lora_compatible: true
      priority: 2

    - name: mxbai-rerank-large-v1
      model_id: mixedbread-ai/mxbai-rerank-large-v1
      lora_compatible: true
      priority: 3

# ============================================================================
# PAPER-GRADE DECISION GATES
# Comprehensive gating framework for retriever finetuning decisions
# ============================================================================

decision_gates:
  # Gate 0: Data integrity check (must pass before any finetuning)
  # If Oracle@ALL < threshold on DEV positives → fix data first
  gate_0_data_integrity:
    oracle_at_all_threshold: 0.99
    action_if_below: "fix_sentence_alignment_or_segmentation"
    description: "Gold must be present when including all sentences"

  # Gate 1: Can we just rerank everything cheaply?
  # If K_budget >= L_p95 → no retriever finetuning needed for recall
  gate_1_rerank_all:
    # K_budget: max candidates to pass to reranker (compute budget)
    k_budget: 10
    # L_p95 threshold: if median post has <= this many sentences, rerank all
    l_p95_threshold: 30
    action_if_budget_covers: "skip_retriever_finetune_focus_on_reranker"
    description: "Reranker can score all sentences for most posts"

  # Gate 2: Retrieval bottleneck under real compute budget
  # Only relevant if K_budget < L_p95
  gate_2_retrieval_bottleneck:
    # Oracle@K_budget thresholds
    oracle_threshold_high: 0.97   # No finetune if >= this
    oracle_threshold_mid: 0.92    # Try cheaper fixes first
    oracle_threshold_low: 0.92    # Finetune if < this
    actions:
      above_high: "skip_retriever_finetune"
      mid_range: "try_cheaper_fixes_first"  # increase K, improve fusion
      below_low: "retriever_finetuning_recommended"

  # Gate 3: End-to-end sensitivity check (most decisive)
  # Compare DeployF1(ALL) vs DeployF1(K_budget)
  gate_3_e2e_sensitivity:
    # Gap threshold in absolute F1 points
    deploy_f1_gap_threshold: 1.0
    action_if_gap_large: "retrieval_is_bottleneck"
    action_if_gap_small: "retriever_not_main_bottleneck"
    description: "Would a perfect retriever help?"

  # Gate 4: Empty-heavy deployment risk (critical for high-empty datasets)
  gate_4_empty_fpr:
    # Acceptable FPR increase tolerance
    empty_fpr_tolerance: 0.005  # 0.5% absolute
    action_if_fpr_increases: "retriever_finetune_harmful_without_recalibration"
    description: "Retriever changes must not worsen empty-post handling"

  # Combined decision rule (paper-defensible):
  # Finetune retriever IFF:
  #   1. Gate 0 passes (Oracle@ALL >= 0.99), AND
  #   2. Either:
  #      a. K_budget < L_p95 AND Oracle@K_budget < 0.92, OR
  #      b. DeployF1(ALL) - DeployF1(K_budget) >= 1.0
  #   3. After retuning postprocess, EmptyFPR does not worsen beyond tolerance
  combined_rule:
    require_gate_0_pass: true
    require_gate_1_or_gate_2: true
    require_gate_4_pass: true

# Legacy gates (retained for backward compatibility)
decision_gates_legacy:
  D2_retriever_ceiling:
    oracle_recall_20_threshold: 0.85
    action_if_below: "retriever_finetuning_required"

  D3_multiquery:
    oracle_recall_improvement_threshold: 0.005
    latency_increase_max_factor: 3.0

  D4_reranker:
    significance_p_threshold: 0.05
    seed_stability_max_std: 0.02

  D5_retriever_finetune:
    oracle_recall_improvement_threshold: 0.01
    downstream_f1_improvement_threshold: 0.01

  D6_ensemble:
    nested_cv_overfit_threshold: 0.05

  D7_diversity:
    f1_loss_tolerance: 0.005
    redundancy_reduction_threshold: 0.1

  D8_abstention:
    false_evidence_improvement_threshold: 0.1

  D9_gnn:
    deployment_improvement_threshold: 0.02
