# Stage C: Jina-v3 Reranker Training with LoRA
# Memory-optimized config for RTX 5090 (32GB VRAM)

enabled: true

paths:
  data_dir: data
  groundtruth: data/groundtruth/evidence_sentence_groundtruth.csv
  sentence_corpus: data/groundtruth/sentence_corpus.jsonl
  criteria: data/DSM5/MDD_Criteira.json
  hpo_output_dir: outputs/hpo

models:
  # Jina-v3 is 0.6B parameters (Qwen3-0.6B based)
  jina_v3: jinaai/jina-reranker-v3

data:
  max_candidates: 32  # Increased for RTX 5090

split:
  seed: 42
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1

# PEFT/LoRA configuration (MANDATORY for maxout)
peft:
  enable: true
  method: lora  # lora or qlora
  r: [16, 32, 64]  # More options for HPO
  alpha: [16, 32, 64]
  dropout: [0.0, 0.05, 0.1]
  target_modules: null  # auto-detect for Qwen3

# Memory optimization - optimized for RTX 5090 32GB
memory:
  use_bf16: true
  gradient_checkpointing: true
  gradient_accumulation_steps: 2  # Reduced for faster updates

# Search space - tuned for RTX 5090 with grouped training data
# Each batch_size of examples -> many more actual pairs (32 candidates per example)
search_space:
  max_length: [512]  # Fixed for memory predictability
  batch_size: [2, 4, 8]  # Realistic for 32 candidates per example
  num_epochs: [1, 3]  # [min, max] for suggest_int (not categorical list)
  learning_rate: [0.00001, 0.0001]  # [min, max] for suggest_float
  weight_decay: [0.00001, 0.01]
  max_pairs_per_group: 32
  training_mode: [pointwise, pairwise]  # Search over both modes
